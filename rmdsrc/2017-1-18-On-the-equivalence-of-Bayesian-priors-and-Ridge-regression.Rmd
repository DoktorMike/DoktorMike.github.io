---
title: "On the equivalence of Bayesian priors and Ridge regression"
author: "Dr. Michael Green"
date: "Jan 18, 2017"
output: html_document
layout: post
published: false
status: publish
use_math: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(rstan)
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)
library(dautility)
library(damodel)
library(nloptr)
rstan_options(auto_write = TRUE)
```

# A probabilistic formulation

Any regression problem can be expressed as an implementation of a probabilistic formulation. For instance what we typically have at our hand is a dependent variable $y$, a matrix $X$ of covariates and a parameter vector $\beta$. The dependent variable consists of data we would like to learn something about or be able to explain. As such we wish to model it's dynamics via the $\beta$ through $X$. The joint probability distribution for these three ingredients is given simply as $p(y, X, \beta)$. This is the most general form of representing a regression problem probabilistically. However, it's not very useful, so in order to make it a bit more tangible let's decompose this joint probability like this.

$$p(y, X, \beta)=p(\beta|y, X)p(y, X)=p(\beta|y, X)p(y)p(X)$$

In this view it is clear that we want to learn something about $\beta$ since that's the unknowns. The other parts we have observed data on. So we would like to say something clever about $p(\beta|y, X)$. How do we go about doing that? Well for starters we need to realize that $p(y, X, \beta)$ can actually be written as 

$$p(y, X, \beta)=p(y|\beta, X)p(\beta, X)=p(y|\beta, X)p(\beta)p(X)$$ 

which means that $$p(\beta|y, X)p(y)p(X)=p(y|\beta, X)p(\beta)p(X)$$ and therefor $$p(\beta|y, X)=\frac{p(y|\beta, X)p(\beta)}{p(y)}$$ which is just a derivation of Baye's rule. Now we actually have something a bit more useful at our hands which is ready to be interpreted and implemented. What do I mean by implemented? Seems like an odd thing to say about probability distributions right? As weird as it may seem we actually haven't given the probability distributions a concise mathematical representation. This is of course necessary for any kind of inference. So let's get to it. The first term I would like to describe is the likelihood i.e. the $p(y|\beta, X)$ which describes the likelihood of observing the data given the covariance matrix $X$ and a set of parameters $\beta$. For simplicity let's say this probability distribution is gaussian thus taking the following form $p(y|\beta, X)=\mathcal{N}(y-\beta X; 0, \sigma)$. This corresponds to setting up a measurement model $y_t = \beta x_t + \epsilon$ where $\epsilon=\mathcal{N}(0, \sigma)$.

The second term in the nominator on the right hand side is our prior $p(\beta)$ which we will also consider gaussian. Thus, we will set $p(\beta)=\mathcal{N}(0, \alpha I)$ indicating that the parameters are independant from each other and most likely centered around $0$ with a known standard deviation of $\alpha$. The last term is the denominator $p(y)$ which in this setting functions as the evidence. This is also the normalizing constant that makes sure that we can interpret the right hand side probabilistically.

That's it! We now have the pieces we need to push the inference button. This is often for more complicated models done by utilizing Markov Chain Monte Carlo methods to sample the distributions. If we are not interested in the distribution but only the average estimates for the parameters we can just turn this into an optimization problem instead by realizing that $$p(\beta|y, X)=\frac{p(y|\beta, X)p(\beta)}{p(y)}\propto p(y|\beta, X)p(\beta)$$ since $p(y)$ just functions as a normalizing constant and doesn't change the location of the $\beta$ that would yield the maximum probability. Thus we can set up the optimization problem as $$\mathcal{L}(\beta)=\prod_{t=1}^T \mathcal{N}(y_t-\beta x_t; 0, \sigma)\mathcal{N}(\beta; 0, \alpha I)$$ and maximize this function. Normally when we solve optimization problems it's easier and nicer to turn it into a minimization problem instead of a maximization problem. This is easily done by minimizing $$-\ln \mathcal{L}(\beta)=-\sum_{t=1}^T \ln \mathcal{N}(y_t-\beta x_t; 0, \sigma)- \ln\mathcal{N}(\beta; 0, \alpha I)$$ as opposed to the equation before. For the sake of clarity let's assume from now on that we only have one independent variable and only one parameter $\beta$. I AM HERE!!!!!!!



