---
title: "A first look at Edward!"
author: "Dr. Michael Green"
date: "Feb 19, 2017"
output: html_document
layout: post
published: false
status: process
use_math: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(rstan)
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)
library(dautility)
library(damodel)
library(nloptr)
rstan_options(auto_write = TRUE)
```

# Motivation

There's a new kid on the inference block called "Edward" who is full of potential and promises of merging probabilistic programming, computational graphs and inference! There's also talk of a 35 times speed up compared to our good old reliable fellow "Stan". Today I will run some comparisons for problems that currently interest me namely time series with structural hyperparameters.

To start things off and make sure we have all our ducks in a row for running edward we need to install it using the python installer called pip which is available in most linux distros. I will use pip3 here because I use python3 instead of python2. It shouldn't matter which one you choose though. So go ahead and install "Edward".

```{bash installedward, eval=FALSE, include=TRUE}
sudo pip3 install edward
```

If you ran this in the console you should now have a working version of Edward installed in your python environment. So far so good. Just to make sure it works we will run a small Bayesian Neural Network with Gaussian priors for the weights. This is the standard example from Edwards web page. It uses a Variational Inference approach to turn the sampling problem into an optimization problem by approximating the target posterior by a multivariate Gaussian. This approach works amazingly well for quite a few problems. Try to run the code below and check it out. 

```{r engine='python', engine.path='python3', cache=FALSE, eval=FALSE}
import numpy as np

x_train = np.linspace(-3, 3, num=50)
y_train = np.cos(x_train) + np.random.normal(0, 0.1, size=50)
x_train = x_train.astype(np.float32).reshape((50, 1))
y_train = y_train.astype(np.float32).reshape((50, 1))

import tensorflow as tf
from edward.models import Normal

W_0 = Normal(mu=tf.zeros([1, 2]), sigma=tf.ones([1, 2]))
W_1 = Normal(mu=tf.zeros([2, 1]), sigma=tf.ones([2, 1]))
b_0 = Normal(mu=tf.zeros(2), sigma=tf.ones(2))
b_1 = Normal(mu=tf.zeros(1), sigma=tf.ones(1))

x = x_train
y = Normal(mu=tf.matmul(tf.tanh(tf.matmul(x, W_0) + b_0), W_1) + b_1, sigma=0.1)

qW_0 = Normal(mu=tf.Variable(tf.zeros([1, 2])),
              sigma=tf.nn.softplus(tf.Variable(tf.zeros([1, 2]))))
qW_1 = Normal(mu=tf.Variable(tf.zeros([2, 1])),
              sigma=tf.nn.softplus(tf.Variable(tf.zeros([2, 1]))))
qb_0 = Normal(mu=tf.Variable(tf.zeros(2)),
              sigma=tf.nn.softplus(tf.Variable(tf.zeros(2))))
qb_1 = Normal(mu=tf.Variable(tf.zeros(1)),
              sigma=tf.nn.softplus(tf.Variable(tf.zeros(1))))

import edward as ed

inference = ed.KLqp({W_0: qW_0, b_0: qb_0,
                     W_1: qW_1, b_1: qb_1}, data={y: y_train})
inference.run(n_iter=1000)

# Get the data into R since plotting in python sucks!
import pandas as pd
mydf=pd.DataFrame(outputs)
mydf.to_csv("mydf.csv")
```


```{r}
library(ggplot2)

# Read from feather and plot
mydf <- read.csv("mydf.csv")[,-1]
# ggplot(flights, aes(carrier, arr_delay)) + geom_point() + geom_jitter()
```
